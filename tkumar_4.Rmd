---
title: "ML Assignment 4"
output:
  pdf_document: default
  word_document: default
---
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Loading the Data
```{r}
rm(list = ls())

library(tidyverse)
#install.packages("factoextra")
library(factoextra)
library(ISLR)
set.seed(123)

DFUniver<-read.csv("Universities.csv")
colnames(DFUniver)
#summary(DFUniver)

#Changing the column names to suitable ones.
DFUniver<-DFUniver%>%rename(
  Pub.Private=Public..1...Private..2.,
  ApplRec=X..appli..rec.d,
  ApplAccept=X..appl..accepted,
  NewStdEnr=X..new.stud..enrolled,
  Top10=X..new.stud..from.top.10.,
  Top25=X..new.stud..from.top.25.,
  FTUnderG=X..FT.undergrad,
  PTUnderG=X..PT.undergrad,
  InStateFee=in.state.tuition,
  OutStateFee=out.of.state.tuition,
  BookCost=estim..book.costs,
  PerCost=estim..personal..,
  PHD=X..fac..w.PHD,
  StFactRatio=stud..fac..ratio
)

colnames(DFUniver)


```
Removing missing records from the Dataset (Measurements)
```{r}
#Total NULL fields in the data frame 
count(DFUniver[!complete.cases(DFUniver),])

#Ipute the NULL values
DFUniver1<-na.omit(DFUniver) 

```

Finding the Data Summary and Measure of Dependence
```{r}
#Summary Data
summary(DFUniver1)

#Finding the correlation between the data set
#Selecting numerical columns only 

DFNumerical<-DFUniver1[,c(-1,-2)]
library(corrplot)
corrplot(cor(DFNumerical), method = "color")

```
In the correlation graph, Darker Blue(+1) and Dark Orange(-1) shows the higher correlated data. Using this data to understand any correlation among the column data.

Applying K-means clustering for Numeric Data
```{r}
#Scaling the Data
DFNumerical<-scale(DFNumerical)

#Distance Between Observations
distance <- get_dist(DFNumerical)

fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))

#Finding Kmeans using cluster size =4

k4 <- kmeans(DFNumerical, centers = 4, nstart = 25) # k = 4, number of restarts = 25
str(k4)

# Visualize the output

k4$centers # output the centers

#number of Universities in each cluster
k4$size

# Visualize the cluster output 

fviz_cluster(k4, data =DFNumerical)

```

Comparision different cluster values

```{r}
k2 <- kmeans(DFNumerical, centers = 2, nstart = 25)
k3 <- kmeans(DFNumerical, centers = 3, nstart = 25)
k4 <- kmeans(DFNumerical, centers = 4, nstart = 25)
k5 <- kmeans(DFNumerical, centers = 5, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = DFNumerical) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = DFNumerical) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = DFNumerical) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = DFNumerical) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```
From the above comparison it seems that 3 clusters would be good. 

```{r}
set.seed(123)
#Finding optimal number of clusters - Elbow Method
fviz_nbclust(DFNumerical, kmeans, method = "wss")

#From the Elbow method it seems 3 or 4 clusters would be optimum. From previous cluster plotting we have seen that optimal cluster size would be 3. 
```

Using the categorical measurements that were not used i n the analysis (State and
Private/Public) to characterize the different clusters.

```{r}
#State wise values present in the cluster
table(DFUniver1$State, k3$cluster)

#Merging the clusters to the original Dat frame
Clusters<-data.frame(k3$cluster)
Clusters<-Clusters%>%rename(clusters=k3.cluster)
UnivAnalysis<-cbind(DFUniver1, Clusters)
head(UnivAnalysis)
#Cluster Summary Analysis

ClusterStat<-UnivAnalysis%>%group_by(clusters)%>%summarise(Acceptance_rate=sum(ApplAccept)/sum(ApplRec), AvgOutStateTution=mean(OutStateFee),AvgInStateTution=mean(InStateFee), AvgGradRate=mean(Graduation.rate))

ClusterStat

```
Use the categorical measurements that were not used i n the analysis (State and
Private/Public) to characterize the different clusters. Is there any relationship between the
clusters and the categorical information?

```{r}
PublicPrivate<-UnivAnalysis%>%group_by(clusters)%>%summarise(Acceptance_rate=sum(ApplAccept)/sum(ApplRec), AvgOutStateTution=mean(OutStateFee),AvgInStateTution=mean(InStateFee), AvgGradRate=mean(Graduation.rate), PublicUnivCount=sum(Pub.Private==1), PrivateUnivCount=sum(Pub.Private==2))

PublicPrivate
```

Consider Tufts University, which is missing some information. Compute the Euclidean
distance of this record from each of the clusters that you found above (using only the
measurements that you have). Which cluster is it closest to? Impute the missing values for
Tufts by taking the average of the cluster on those measurements.



