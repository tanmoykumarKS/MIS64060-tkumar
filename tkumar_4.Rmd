---
title: "ML Assignment 4"
output:
  pdf_document: default
  word_document: default
---
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Loading the Data
```{r}
rm(list = ls())

library(tidyverse)
#install.packages("factoextra")
library(factoextra)
library(ISLR)
set.seed(123)

DFUniver<-read.csv("Universities.csv")
colnames(DFUniver)
#summary(DFUniver)

#Changing the column names to suitable ones.
DFUniver<-DFUniver%>%rename(
  Pub.Private=Public..1...Private..2.,
  ApplRec=X..appli..rec.d,
  ApplAccept=X..appl..accepted,
  NewStdEnr=X..new.stud..enrolled,
  Top10=X..new.stud..from.top.10.,
  Top25=X..new.stud..from.top.25.,
  FTUnderG=X..FT.undergrad,
  PTUnderG=X..PT.undergrad,
  InStateFee=in.state.tuition,
  OutStateFee=out.of.state.tuition,
  BookCost=estim..book.costs,
  PerCost=estim..personal..,
  PHD=X..fac..w.PHD,
  StFactRatio=stud..fac..ratio
)

colnames(DFUniver)


```
Removing missing records from the Dataset (Measurements)
```{r}
#Total NULL fields in the data frame 
count(DFUniver[!complete.cases(DFUniver),])

#Ipute the NULL values
DFUniver1<-na.omit(DFUniver) 

```

Finding the Data Summary and Measure of Dependence
```{r}
#Summary Data
summary(DFUniver1)

#Finding the correlation between the data set
#Selecting numerical columns only 

DFNumerical<-DFUniver1[,c(-1,-2)]
library(corrplot)
corrplot(cor(DFNumerical), method = "color")



```
In the correlation graph, Darker Blue(+1) and Dark Orange(-1) shows the higher correlated data. Using this data to understand any correlation among the column data.

Applying K-means clustering for Numeric Data
```{r}
#Scaling the Data
DFNumerical<-scale(DFNumerical)

#Distance Between Observations
distance <- get_dist(DFNumerical)

fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))

#Finding Kmeans using cluster size =4

k4 <- kmeans(DFNumerical, centers = 4, nstart = 25) # k = 4, number of restarts = 25
str(k4)

# Visualize the output

k4$centers # output the centers

#number of Universities in each cluster
k4$size

# Visualize the output - Application Accepted vs Out of State Fee

fviz_cluster(k4, data =DFNumerical)

```

Comparision different cluster values

```{r}
k2 <- kmeans(DFNumerical, centers = 2, nstart = 25)
k3 <- kmeans(DFNumerical, centers = 3, nstart = 25)
k4 <- kmeans(DFNumerical, centers = 4, nstart = 25)
k5 <- kmeans(DFNumerical, centers = 5, nstart = 25)

# plots to compare
p1 <- fviz_cluster(k2, geom = "point", data = DFNumerical) + ggtitle("k = 2")
p2 <- fviz_cluster(k3, geom = "point",  data = DFNumerical) + ggtitle("k = 3")
p3 <- fviz_cluster(k4, geom = "point",  data = DFNumerical) + ggtitle("k = 4")
p4 <- fviz_cluster(k5, geom = "point",  data = DFNumerical) + ggtitle("k = 5")

library(gridExtra)
grid.arrange(p1, p2, p3, p4, nrow = 2)
```
From the above comparison it seems that 3 clusters would be good. 

```{r}
set.seed(123)
#Finding optimal number of clusters - Elbow Method
fviz_nbclust(DFNumerical, kmeans, method = "wss")

#From the Elbow method it seems 4 clusters would be optimum.
```
```{r}
DFUniver1 %>%
  mutate(Cluster = k4$cluster) %>%
  group_by(Cluster) %>%
  summarise_all("mean")

```


Using the categorical measurements that were not used i n the analysis (State and
Private/Public) to characterize the different clusters.

```{r}
#State wise values present in the cluster
table(DFUniver1$State, k4$cluster)

```

Tufts University data imputation 

```{r}
# Initial Dataframe DFUniver with no imputation 
library(flexclust)
set.seed(123)
#kmeans clustering, using Euclidean distance
k5 = kcca(DFNumerical, k=5, kccaFamily("kmeans"))
k5

#Apply the predict() function
clusters_index <- predict(k5)
image(k5)
#points(df, col=clusters_index, pch=19, cex=0.3)
```


