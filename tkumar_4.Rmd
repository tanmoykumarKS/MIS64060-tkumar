---
title: "ML Assignment 4"
output:
  word_document: default
  pdf_document: default
---
## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

Loading the Data
```{r}
rm(list = ls())

library(tidyverse)
#install.packages("factoextra")
library(factoextra)
library(ISLR)
set.seed(123)

DFUniver<-read.csv("Universities.csv")
colnames(DFUniver)
#summary(DFUniver)

#Changing the column names to suitable ones.
DFUniver<-DFUniver%>%rename(
  Pub.Private=Public..1...Private..2.,
  ApplRec=X..appli..rec.d,
  ApplAccept=X..appl..accepted,
  NewStdEnr=X..new.stud..enrolled,
  Top10=X..new.stud..from.top.10.,
  Top25=X..new.stud..from.top.25.,
  FTUnderG=X..FT.undergrad,
  PTUnderG=X..PT.undergrad,
  InStateFee=in.state.tuition,
  OutStateFee=out.of.state.tuition,
  BookCost=estim..book.costs,
  PerCost=estim..personal..,
  PHD=X..fac..w.PHD,
  StFactRatio=stud..fac..ratio
)

colnames(DFUniver)


```
Removing missing records from the Dataset (Measurements)
```{r}
#Total NULL fields in the data frame 
count(DFUniver[!complete.cases(DFUniver),])

#Ipute the NULL values
DFUniver1<-na.omit(DFUniver) 

```

Finding the Data Summary and Measure of Dependence
```{r}
#Summary Data
summary(DFUniver1)

#Subsetting the data 

DFNumerical<-subset(DFUniver1, select = -c(1,2,3)) 

#Finding the correlation between the data set
library(corrplot)
corrplot(cor(DFNumerical), method = "color")

```
In the correlation graph, Darker Blue(+1) and Dark Orange(-1) shows the higher correlated data. Using this data to understand any correlation among the column data.

Applying K-means clustering for Numeric Data
```{r}
#Scaling the Data
DFNumerical<-scale(DFNumerical)

#Distance Between Observations
distance <- get_dist(DFNumerical)

fviz_dist(distance, gradient = list(low = "#00AFBB", mid = "white", high = "#FC4E07"))

```

Comparison different cluster values

```{r}

k2 <- kmeans(DFNumerical, centers = 2, nstart = 25)
k3 <- kmeans(DFNumerical, centers = 3, nstart = 25)
k4 <- kmeans(DFNumerical, centers = 4, nstart = 25)
k5 <- kmeans(DFNumerical, centers = 5, nstart = 25)
k6 <- kmeans(DFNumerical, centers = 5, nstart = 25)

# plots to compare
p2 <- fviz_cluster(k2, geom = "point", data = DFNumerical) + ggtitle("k = 2")
p3 <- fviz_cluster(k3, geom = "point",  data = DFNumerical) + ggtitle("k = 3")
p4 <- fviz_cluster(k4, geom = "point",  data = DFNumerical) + ggtitle("k = 4")
p5 <- fviz_cluster(k5, geom = "point",  data = DFNumerical) + ggtitle("k = 5")
p6 <- fviz_cluster(k6, geom = "point",  data = DFNumerical) + ggtitle("k = 6")

library(gridExtra)
grid.arrange(p2, p3, p4, p5, p6, nrow = 2)
```
From the above comparison it seems that 3 clusters would be good. Determining Optimal Cluster using Elbow and Silhouette method. 

```{r}
set.seed(123)
#Finding optimal number of clusters - Elbow Method
fviz_nbclust(DFNumerical, kmeans, method = "wss")

#Determining Optimal Cluster by Average Silhouette Method
fviz_nbclust(DFNumerical, kmeans, method = "silhouette")

#From the Silhouette method it seems 3 no. of clusters would be optimum. From previous cluster plotting we have seen that optimal cluster size would be 3. 

#3 clusters are the reasonable for this data and the optimal K is 3.
k3 <- kmeans(DFNumerical, centers = 3, nstart = 25)
# Optimal Visualization
fviz_cluster(k3,data = DFNumerical) 
```
Compare the summary statistics for each cluster and describe each cluster i n this context
(e.g., “Universities with high tuition, l ow acceptance rate...”).

```{r}

k3 <- kmeans(DFNumerical, centers = 3, nstart = 25)
# centers
k3$centers 

# Count of Clusters
k3$size 

#Visualize the cluster
fviz_cluster(k3, data = DFNumerical)
#k3

```

Using the categorical measurements that were not used i n the analysis (State and
Private/Public) to characterize the different clusters.

```{r}
#State wise values present in the cluster
table(DFUniver1$State, k3$cluster)

#Merging the clusters to the original Data frame
Clusters<-data.frame(k3$cluster)

Clusters<-Clusters%>%rename(clusters=k3.cluster)

UnivAnalysis<-cbind(DFUniver1, Clusters)
head(UnivAnalysis)

#Cluster Summary Analysis
ClusterStat<-UnivAnalysis%>%group_by(clusters)%>%summarise(Acceptance_rate=sum(ApplAccept)/sum(ApplRec), AvgOutStateTution=mean(OutStateFee),AvgInStateTution=mean(InStateFee), AvgGradRate=mean(Graduation.rate))

ClusterStat

#Findig the Public and Private Universities present in the clusters
ClusterStat<-UnivAnalysis%>%group_by(clusters,Pub.Private)%>%summarise(Univ_Count=n())

ClusterStat

#Yes, there is a relationship between clusters and categorical information. 

```
Consider Tufts University, which is missing some information. Compute the Euclidean
distance of this record from each of the clusters that you found above (using only the
measurements that you have). Which cluster is it closest to? Impute the missing values for
Tufts by taking the average of the cluster on those measurements.




